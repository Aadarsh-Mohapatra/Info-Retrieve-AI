{"cells":[{"cell_type":"markdown","metadata":{"id":"G5JgyfeVmda4"},"source":["# IRS - GEMMA"]},{"cell_type":"markdown","metadata":{"id":"WuUn-XcEIpVG"},"source":["## Setup and Installations"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["E:\\Github_Repo\\Info-Retrieve-AI\n"]},{"name":"stderr","output_type":"stream","text":["e:\\Github_Repo\\Info-Retrieve-AI\\venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n","  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"]}],"source":["%cd E:\\Github_Repo\\Info-Retrieve-AI"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34160,"status":"ok","timestamp":1716055676190,"user":{"displayName":"Aadarsh Mohapatra","userId":"03692433235726147105"},"user_tz":-330},"id":"ut_3sb4Tz4es","outputId":"c2646d37-0cc9-4944-bbfb-600b4646991c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: deeplake==3.9.3 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 1)) (3.9.3)\n","Requirement already satisfied: langchain==0.1.3 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 2)) (0.1.3)\n","Requirement already satisfied: langchain-community==0.0.20 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 3)) (0.0.20)\n","Requirement already satisfied: langchain-core==0.1.23 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.1.23)\n","Requirement already satisfied: langchain-google-genai==0.0.11 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 5)) (0.0.11)\n","Requirement already satisfied: langsmith==0.0.87 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.0.87)\n","Requirement already satisfied: lxml==4.9.4 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 7)) (4.9.4)\n","Requirement already satisfied: nltk==3.8.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 8)) (3.8.1)\n","Requirement already satisfied: numpy==1.26.2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 9)) (1.26.2)\n","Requirement already satisfied: openai==0.28.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 10)) (0.28.0)\n","Requirement already satisfied: pydantic==2.5.3 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 11)) (2.5.3)\n","Requirement already satisfied: pydantic_core==2.14.6 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 12)) (2.14.6)\n","Requirement already satisfied: PyMuPDF==1.23.21 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 13)) (1.23.21)\n","Requirement already satisfied: pypdf==3.17.4 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 14)) (3.17.4)\n","Requirement already satisfied: pypdfium2==4.25.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 15)) (4.25.0)\n","Requirement already satisfied: scipy==1.12.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 16)) (1.12.0)\n","Requirement already satisfied: sentence-transformers==2.3.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 17)) (2.3.1)\n","Requirement already satisfied: tiktoken==0.5.2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 18)) (0.5.2)\n","Requirement already satisfied: transformers==4.36.2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 19)) (4.36.2)\n","Requirement already satisfied: pinecone-client==4.0.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 20)) (4.0.0)\n","Requirement already satisfied: streamlit in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 21)) (1.35.0)\n","Requirement already satisfied: pyngrok in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 22)) (7.1.6)\n","Requirement already satisfied: matplotlib in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 23)) (3.9.0)\n","Requirement already satisfied: seaborn in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 24)) (0.13.2)\n","Requirement already satisfied: beautifulsoup4 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from -r requirements.txt (line 25)) (4.12.3)\n","Requirement already satisfied: pillow~=10.2.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from deeplake==3.9.3->-r requirements.txt (line 1)) (10.2.0)\n","Requirement already satisfied: boto3 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from deeplake==3.9.3->-r requirements.txt (line 1)) (1.34.125)\n","Requirement already satisfied: click in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from deeplake==3.9.3->-r requirements.txt (line 1)) (8.1.7)\n","Requirement already satisfied: pathos in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from deeplake==3.9.3->-r requirements.txt (line 1)) (0.3.2)\n","Requirement already satisfied: humbug>=0.3.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from deeplake==3.9.3->-r requirements.txt (line 1)) (0.3.2)\n","Requirement already satisfied: tqdm in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from deeplake==3.9.3->-r requirements.txt (line 1)) (4.66.4)\n","Requirement already satisfied: lz4 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from deeplake==3.9.3->-r requirements.txt (line 1)) (4.3.3)\n","Requirement already satisfied: pyjwt in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from deeplake==3.9.3->-r requirements.txt (line 1)) (2.8.0)\n","Requirement already satisfied: PyYAML>=5.3 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from langchain==0.1.3->-r requirements.txt (line 2)) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from langchain==0.1.3->-r requirements.txt (line 2)) (2.0.30)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from langchain==0.1.3->-r requirements.txt (line 2)) (3.9.5)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from langchain==0.1.3->-r requirements.txt (line 2)) (0.6.7)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from langchain==0.1.3->-r requirements.txt (line 2)) (1.33)\n","Requirement already satisfied: requests<3,>=2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from langchain==0.1.3->-r requirements.txt (line 2)) (2.32.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from langchain==0.1.3->-r requirements.txt (line 2)) (8.3.0)\n","Requirement already satisfied: anyio<5,>=3 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from langchain-core==0.1.23->-r requirements.txt (line 4)) (4.4.0)\n","Requirement already satisfied: packaging<24.0,>=23.2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from langchain-core==0.1.23->-r requirements.txt (line 4)) (23.2)\n","Requirement already satisfied: google-generativeai<0.5.0,>=0.4.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from langchain-google-genai==0.0.11->-r requirements.txt (line 5)) (0.4.1)\n","Requirement already satisfied: joblib in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from nltk==3.8.1->-r requirements.txt (line 8)) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from nltk==3.8.1->-r requirements.txt (line 8)) (2024.5.15)\n","Requirement already satisfied: annotated-types>=0.4.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from pydantic==2.5.3->-r requirements.txt (line 11)) (0.7.0)\n","Requirement already satisfied: typing-extensions>=4.6.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from pydantic==2.5.3->-r requirements.txt (line 11)) (4.12.2)\n","Requirement already satisfied: PyMuPDFb==1.23.9 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from PyMuPDF==1.23.21->-r requirements.txt (line 13)) (1.23.9)\n","Requirement already satisfied: torch>=1.11.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from sentence-transformers==2.3.1->-r requirements.txt (line 17)) (2.3.1)\n","Requirement already satisfied: scikit-learn in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from sentence-transformers==2.3.1->-r requirements.txt (line 17)) (1.5.0)\n","Requirement already satisfied: sentencepiece in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from sentence-transformers==2.3.1->-r requirements.txt (line 17)) (0.2.0)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from sentence-transformers==2.3.1->-r requirements.txt (line 17)) (0.23.3)\n","Requirement already satisfied: filelock in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from transformers==4.36.2->-r requirements.txt (line 19)) (3.14.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from transformers==4.36.2->-r requirements.txt (line 19)) (0.15.2)\n","Requirement already satisfied: safetensors>=0.3.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from transformers==4.36.2->-r requirements.txt (line 19)) (0.4.3)\n","Requirement already satisfied: certifi>=2019.11.17 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from pinecone-client==4.0.0->-r requirements.txt (line 20)) (2024.6.2)\n","Requirement already satisfied: urllib3>=1.26.5 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from pinecone-client==4.0.0->-r requirements.txt (line 20)) (2.2.1)\n","Requirement already satisfied: altair<6,>=4.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (5.3.0)\n","Requirement already satisfied: blinker<2,>=1.0.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (1.8.2)\n","Requirement already satisfied: cachetools<6,>=4.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (5.3.3)\n","Requirement already satisfied: pandas<3,>=1.3.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (2.2.2)\n","Requirement already satisfied: protobuf<5,>=3.20 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (4.25.3)\n","Requirement already satisfied: pyarrow>=7.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (16.1.0)\n","Requirement already satisfied: rich<14,>=10.14.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (13.7.1)\n","Requirement already satisfied: toml<2,>=0.10.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (0.10.2)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (3.1.43)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (0.9.1)\n","Requirement already satisfied: tornado<7,>=6.0.3 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (6.4.1)\n","Requirement already satisfied: watchdog>=2.1.5 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from streamlit->-r requirements.txt (line 21)) (4.0.1)\n","Requirement already satisfied: contourpy>=1.0.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 23)) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 23)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 23)) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 23)) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 23)) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from matplotlib->-r requirements.txt (line 23)) (2.9.0.post0)\n","Requirement already satisfied: soupsieve>1.2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from beautifulsoup4->-r requirements.txt (line 25)) (2.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.3->-r requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.3->-r requirements.txt (line 2)) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.3->-r requirements.txt (line 2)) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.3->-r requirements.txt (line 2)) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.3->-r requirements.txt (line 2)) (1.9.4)\n","Requirement already satisfied: jinja2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 21)) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 21)) (4.22.0)\n","Requirement already satisfied: toolz in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 21)) (0.12.1)\n","Requirement already satisfied: idna>=2.8 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from anyio<5,>=3->langchain-core==0.1.23->-r requirements.txt (line 4)) (3.7)\n","Requirement already satisfied: sniffio>=1.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from anyio<5,>=3->langchain-core==0.1.23->-r requirements.txt (line 4)) (1.3.1)\n","Requirement already satisfied: colorama in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from click->deeplake==3.9.3->-r requirements.txt (line 1)) (0.4.6)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.3->-r requirements.txt (line 2)) (3.21.3)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.3->-r requirements.txt (line 2)) (0.9.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 21)) (4.0.11)\n","Requirement already satisfied: google-ai-generativelanguage==0.4.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11->-r requirements.txt (line 5)) (0.4.0)\n","Requirement already satisfied: google-auth>=2.15.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11->-r requirements.txt (line 5)) (2.30.0)\n","Requirement already satisfied: google-api-core in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11->-r requirements.txt (line 5)) (2.19.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11->-r requirements.txt (line 5)) (1.23.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.3.1->-r requirements.txt (line 17)) (2024.6.0)\n","Requirement already satisfied: jsonpointer>=1.9 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.3->-r requirements.txt (line 2)) (3.0.0)\n","Requirement already satisfied: pytz>=2020.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit->-r requirements.txt (line 21)) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit->-r requirements.txt (line 21)) (2024.1)\n","Requirement already satisfied: six>=1.5 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 23)) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from requests<3,>=2->langchain==0.1.3->-r requirements.txt (line 2)) (3.3.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 21)) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 21)) (2.18.0)\n","Requirement already satisfied: greenlet!=0.4.17 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.3->-r requirements.txt (line 2)) (3.0.3)\n","Requirement already satisfied: sympy in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==2.3.1->-r requirements.txt (line 17)) (1.12.1)\n","Requirement already satisfied: networkx in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==2.3.1->-r requirements.txt (line 17)) (3.3)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==2.3.1->-r requirements.txt (line 17)) (2021.4.0)\n","Requirement already satisfied: botocore<1.35.0,>=1.34.125 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from boto3->deeplake==3.9.3->-r requirements.txt (line 1)) (1.34.125)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from boto3->deeplake==3.9.3->-r requirements.txt (line 1)) (1.0.1)\n","Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from boto3->deeplake==3.9.3->-r requirements.txt (line 1)) (0.10.1)\n","Requirement already satisfied: ppft>=1.7.6.8 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from pathos->deeplake==3.9.3->-r requirements.txt (line 1)) (1.7.6.8)\n","Requirement already satisfied: dill>=0.3.8 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from pathos->deeplake==3.9.3->-r requirements.txt (line 1)) (0.3.8)\n","Requirement already satisfied: pox>=0.3.4 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from pathos->deeplake==3.9.3->-r requirements.txt (line 1)) (0.3.4)\n","Requirement already satisfied: multiprocess>=0.70.16 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from pathos->deeplake==3.9.3->-r requirements.txt (line 1)) (0.70.16)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers==2.3.1->-r requirements.txt (line 17)) (3.5.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 21)) (5.0.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11->-r requirements.txt (line 5)) (1.63.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11->-r requirements.txt (line 5)) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11->-r requirements.txt (line 5)) (4.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit->-r requirements.txt (line 21)) (2.1.5)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 21)) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 21)) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 21)) (0.18.1)\n","Requirement already satisfied: mdurl~=0.1 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r requirements.txt (line 21)) (0.1.2)\n","Requirement already satisfied: intel-openmp==2021.* in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers==2.3.1->-r requirements.txt (line 17)) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers==2.3.1->-r requirements.txt (line 17)) (2021.12.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.3->-r requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers==2.3.1->-r requirements.txt (line 17)) (1.3.0)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11->-r requirements.txt (line 5)) (1.64.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11->-r requirements.txt (line 5)) (1.62.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in e:\\github_repo\\info-retrieve-ai\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai==0.0.11->-r requirements.txt (line 5)) (0.6.0)\n"]}],"source":["# Install required packages\n","!pip install -r requirements.txt\n","\n","# Install TensorFlow and Keras\n","!pip install -q -U tensorflow\n","!pip install -q -U keras-nlp\n","!pip install -q -U keras>=3"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"DI5t9CavzmAZ"},"outputs":[],"source":["# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Import necessary libraries\n","import os\n","import config as cfg\n","import pandas as pd\n","import numpy as np\n","import requests\n","from bs4 import BeautifulSoup\n","from sentence_transformers import SentenceTransformer\n","import pinecone\n","from pinecone import Pinecone, ServerlessSpec\n","import google.generativeai as genai\n","\n","# Configure the Gemini API using config.py file\n","genai.configure(api_key=cfg.GOOGLE_API_KEY)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9525,"status":"ok","timestamp":1716055702194,"user":{"displayName":"Aadarsh Mohapatra","userId":"03692433235726147105"},"user_tz":-330},"id":"MZS581Ig1swC","outputId":"5505fce4-0aef-4319-b8c7-a73441111fd5"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'distutils'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Validate installation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39m__version__)\n","File \u001b[1;32me:\\Github_Repo\\Info-Retrieve-AI\\venv\\Lib\\site-packages\\tensorflow\\__init__.py:30\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_inspect\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"]}],"source":["# Validate installation\n","import tensorflow as tf\n","import keras\n","print(\"TensorFlow version:\", tf.__version__)\n","print(\"Keras version:\", keras.__version__)\n","\n","# Import keras_nlp for working with Gemma\n","import keras_nlp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8L7c9KCz9U5","outputId":"9c5f9b33-1001-4448-c394-24cbb690261b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_2b_en/2/download/metadata.json...\n","100%|██████████| 143/143 [00:00<00:00, 38.3kB/s]\n","Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_2b_en/2/download/task.json...\n","Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_2b_en/2/download/config.json...\n","100%|██████████| 555/555 [00:00<00:00, 1.18MB/s]\n","Downloading from https://www.kaggle.com/api/v1/models/keras/gemma/keras/gemma_2b_en/2/download/model.weights.h5...\n","100%|██████████| 4.67G/4.67G [06:31<00:00, 12.8MB/s]\n"]}],"source":["## Gemma Model Initialization\n","\n","# Configuration for Kaggle API\n","os.environ['KAGGLE_KEY'] = cfg.KAGGLE_KEY\n","os.environ['KAGGLE_USERNAME'] = cfg.KAGGLE_USERNAME\n","\n","# Select TensorFlow as the backend\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","\n","# Pre-allocate 100% of GPU memory to minimize memory fragmentation issues\n","os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n","\n","# Set a random seed for reproducibility\n","keras.utils.set_random_seed(42)\n","\n","# Initialize the Gemma model\n","gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n","# gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_1.1_instruct_2b_en\")\n","\n","# Print model summary to confirm the model is loaded correctly\n","gemma_lm.summary()"]},{"cell_type":"markdown","metadata":{"id":"yNBt0VMhjI6z"},"source":["## Web Scrapper"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"922Lu-UyjDY6"},"outputs":[],"source":["class BlogScraper:\n","    def __init__(self, url, headers):\n","        self.url = url\n","        self.headers = headers\n","\n","    def scrape(self):\n","        response = requests.get(self.url, headers=self.headers)\n","        if response.status_code == 200:\n","            soup = BeautifulSoup(response.content, 'html.parser')\n","            box = soup.find('div', class_='gridbox gridbox-170-970')\n","            items = box.find_all('div', class_='card-title headingC sans')\n","\n","            data = []\n","            for index, item in enumerate(items, start=1):\n","                title = item.text.strip()\n","                link = item.find('a')['href']\n","                link_response = requests.get(link, headers=self.headers)\n","                if link_response.status_code == 200:\n","                    link_soup = BeautifulSoup(link_response.content, 'html.parser')\n","                    content = link_soup.find('div', class_='wysiwyg').get_text(separator='\\n').strip()\n","                    data.append({\"Index\": index, \"Heading\": title, \"Hyperlink\": link, \"Content\": content})\n","                else:\n","                    print(f\"Failed to fetch content for hyperlink: {link}\")\n","\n","            return data\n","        else:\n","            print(\"Failed to fetch the webpage.\")\n","            return None"]},{"cell_type":"markdown","metadata":{"id":"bYrGeICY8Teq"},"source":["## BlogIndexer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2YO6SokD26I"},"outputs":[],"source":["# BlogIndexer\n","class BlogIndexer:\n","    def __init__(self, url, headers):\n","        self.scraper = BlogScraper(url, headers)\n","        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n","        self.index_name = \"blog-index\"\n","        self.index = pinecone.Index(name=self.index_name, api_key=cfg.PINECONE_API_KEY, host='https://blog-index-ntt4sfk.svc.aped-4627-b74a.pinecone.io')\n","        self.index.describe_index_stats()\n","\n","    def index_content(self):\n","        data = self.scraper.scrape()\n","        if data:\n","            upsert_data = []\n","            for item in data:\n","                combined_text = f\"{item['Heading']}. {item['Content']}\"\n","                embedding = self.model.encode(combined_text, convert_to_tensor=False)\n","                embedding_list = embedding.tolist()\n","                # Include content in metadata for retrieval in the QA system\n","                upsert_data.append((str(item['Index']), embedding_list, {'content': item['Content']}))\n","            self.index.upsert(vectors=upsert_data)\n","            print(\"Content indexed successfully.\")\n","\n","\n","    def view_scraped_data(self):\n","        data = self.scraper.scrape()\n","        for item in data:\n","            print(item)\n","\n","    def test_embeddings(self):\n","        data = self.scraper.scrape()\n","        for item in data:\n","            embedding = self.model.encode(f\"{item['Heading']}. {item['Content']}\", convert_to_tensor=False)\n","            print(f\"Index: {item['Index']}, Heading: {item['Heading']}, Embedding: {embedding[:5]}...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVDmcmg2IFzj"},"outputs":[],"source":["# Usage\n","indexer = BlogIndexer(url='https://escalent.co/thought-leadership/blog/?industry=automotive-and-mobility', headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"})\n","indexer.view_scraped_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9XgqmMMaPY8a"},"outputs":[],"source":["indexer.index_content()\n","indexer.test_embeddings()"]},{"cell_type":"markdown","metadata":{"id":"_jqDPJYnoehg"},"source":["## QASystem- Gemma"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w139xM_PogWm"},"outputs":[],"source":["import pandas as pd\n","\n","class QASystem:\n","    def __init__(self, model, indexer_instance):\n","        self.model = model\n","        self.indexer = indexer_instance\n","        self.logs = pd.DataFrame(columns=['Query', 'Response'])\n","\n","    def query_to_embedding(self, query):\n","        # Generate embedding for the query\n","        embedding = self.indexer.model.encode(query, convert_to_tensor=False)\n","        return embedding.tolist()\n","\n","    def retrieve_context(self, query_embedding, top_k=3):\n","        # Retrieve top k matching contexts from Pinecone\n","        query_results = self.indexer.index.query(vector=query_embedding, top_k=top_k, include_metadata=True)\n","        documents = []\n","        for match in query_results.get('matches', []):\n","            documents.append(match['metadata']['content'])\n","        return \" \".join(documents)\n","\n","    def answer_query(self, query):\n","        print(\"Generating query embedding...\")\n","        query_embedding = self.query_to_embedding(query)\n","        print(\"Retrieving context...\")\n","        context = self.retrieve_context(query_embedding)\n","        if not context:\n","            response_text = \"I couldn't find enough information to answer your question.\"\n","        else:\n","            augmented_query = \"\\n\\n---\\n\\n\".join(contexts) + \"\\n\\n---\\n\\n\" + query\n","            prompt = f\"You are a Question and Answering bot designed to answer questions using the provided context. Do not answer questions that are asked outside the context. Here's the user question:\\n\\n{augmented_query}\"\n","            print(\"Generating response based on the context...\")\n","            response = self.model.generate(prompt, max_length=512)\n","            response_text = response[0]['generated_text']\n","            print(\"Response generated.\")\n","        # Log the query and the response\n","        self.logs = pd.concat([self.logs, pd.DataFrame([{'Query': query, 'Response': response_text}])], ignore_index=True)\n","        return response_text\n","\n","    def save_logs_to_csv(self, filename=\"gemma_query_logs.csv\"):\n","        self.logs.to_csv(filename, index=False)\n","        print(f\"Logs saved to {filename}.\")\n","\n","    def print_log(self):\n","        if self.logs.empty:\n","            print(\"No entries in the log.\")\n","        else:\n","            print(self.logs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"46MTx3V4o1xW"},"outputs":[],"source":["# Usage\n","indexer = BlogIndexer(\n","    url='https://escalent.co/thought-leadership/blog/?industry=automotive-and-mobility',\n","    headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n",")\n","\n","qa_system = QASystem(gemma_lm, indexer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0glVS2eP3H_g"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNx3KyWyYkGTF0PBG5MCPxa","collapsed_sections":["yNBt0VMhjI6z","bYrGeICY8Teq"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
